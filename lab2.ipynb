{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization and full text search (FTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is concentrated on using full text search engine (ElasticSearch) to perform basic search operations in a text corpus.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "1. Install ElasticSearch (ES).\n",
    "2. Install an ES plugin for Polish https://github.com/allegro/elasticsearch-analysis-morfologik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define an ES analyzer for Polish texts containing:\n",
    "- standard tokenizer\n",
    "- synonym filter with alternative forms for months, e.g. kwiecień, kwi, IV.\n",
    "- lowercase filter\n",
    "- Morfologik-based lemmatizer\n",
    "- lowercase filter (looks strange, but Morfologi produces capitalized base forms for proper names, so we have to  - lowercase them once more).\n",
    "4. Define another analyzer for Polish, without the synonym filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_settings = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"filter\": {\n",
    "                \"synonym\": {\n",
    "                    # Definicja synonimów dla miesięcy\n",
    "                    \"type\": \"synonym\",\n",
    "                    \"synonyms\": [\n",
    "                        \"styczeń, sty, I\",\n",
    "                        \"luty, lut, II\",\n",
    "                        \"marzec, mar, III\",\n",
    "                        \"kwiecień, kwi, IV\",\n",
    "                        \"maj, V\",\n",
    "                        \"czerwiec, cze, VI\",\n",
    "                        \"lipiec, lip, VII\",\n",
    "                        \"sierpień, sie, VIII\",\n",
    "                        \"wrzesień, wrz, IX\",\n",
    "                        \"październik, paź, X\",\n",
    "                        \"listopad, lis, XI\",\n",
    "                        \"grudzień, gru, XII\"\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"analyzer\": {\n",
    "                # Analizator z synonimami, małymi literami i lematyzacją\n",
    "                \"polish_analyzer_with_synonyms\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\"synonym\", \"lowercase\", \"morfologik_stem\", \"lowercase\"]\n",
    "                },\n",
    "                # Analizator bez synonimów\n",
    "                \"polish_analyzer_without_synonyms\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\"lowercase\", \"morfologik_stem\", \"lowercase\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\" : {\n",
    "        \"properties\": {\n",
    "            # Pole z analizą uwzględniającą synonimy\n",
    "            \"with_synonyms\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"polish_analyzer_with_synonyms\"\n",
    "            },\n",
    "            # Pole z analizą bez synonimów\n",
    "            \"without_synonyms\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"polish_analyzer_without_synonyms\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Define an ES index for storing the contents of the corpus FiQA-PL using both analyzers. Use different names for the fields analyzed with a different pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gboch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'node-1', 'cluster_name': 'my-application-cluster', 'cluster_uuid': 'MTibwZg5SaiWz0u8ARtMDw', 'version': {'number': '8.15.2', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '98adf7bf6bb69b66ab95b761c9e5aadb0bb059a3', 'build_date': '2024-09-19T10:06:03.564235954Z', 'build_snapshot': False, 'lucene_version': '9.11.1', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gboch\\AppData\\Local\\Temp\\ipykernel_4460\\3047365429.py:12: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  es.indices.create(index=index_name, body=analysis_settings, ignore=400)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'fiqa-pl-index'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "print(es.info())\n",
    "\n",
    "index_name = \"fiqa-pl-index\"\n",
    "if es.indices.exists(index=index_name):\n",
    "    es.indices.delete(index=index_name)\n",
    "es.indices.create(index=index_name, body=analysis_settings, ignore=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Load the data to the ES index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>Nie mówię, że nie podoba mi się też pomysł szk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td></td>\n",
       "      <td>Tak więc nic nie zapobiega fałszywym ocenom po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56</td>\n",
       "      <td></td>\n",
       "      <td>Nigdy nie możesz korzystać z FSA dla indywidua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td></td>\n",
       "      <td>Samsung stworzył LCD i inne technologie płaski...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td></td>\n",
       "      <td>Oto wymagania SEC: Federalne przepisy dotycząc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57633</th>\n",
       "      <td>599946</td>\n",
       "      <td></td>\n",
       "      <td>&gt;Cóż, po pierwsze, drogi to coś więcej niż hob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57634</th>\n",
       "      <td>599953</td>\n",
       "      <td></td>\n",
       "      <td>Tak, robią. Na dotacje dla firm farmaceutyczny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57635</th>\n",
       "      <td>599966</td>\n",
       "      <td></td>\n",
       "      <td>&gt;To bardzo smutne, że nie rozumiesz ludzkiej n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57636</th>\n",
       "      <td>599975</td>\n",
       "      <td></td>\n",
       "      <td>„Czy Twój CTO pozwolił dużej grupie użyć „„adm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57637</th>\n",
       "      <td>599987</td>\n",
       "      <td></td>\n",
       "      <td>Zapewnienie rządowi większej kontroli nad dyst...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57638 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          _id title                                               text\n",
       "0           3        Nie mówię, że nie podoba mi się też pomysł szk...\n",
       "1          31        Tak więc nic nie zapobiega fałszywym ocenom po...\n",
       "2          56        Nigdy nie możesz korzystać z FSA dla indywidua...\n",
       "3          59        Samsung stworzył LCD i inne technologie płaski...\n",
       "4          63        Oto wymagania SEC: Federalne przepisy dotycząc...\n",
       "...       ...   ...                                                ...\n",
       "57633  599946        >Cóż, po pierwsze, drogi to coś więcej niż hob...\n",
       "57634  599953        Tak, robią. Na dotacje dla firm farmaceutyczny...\n",
       "57635  599966        >To bardzo smutne, że nie rozumiesz ludzkiej n...\n",
       "57636  599975        „Czy Twój CTO pozwolił dużej grupie użyć „„adm...\n",
       "57637  599987        Zapewnienie rządowi większej kontroli nad dyst...\n",
       "\n",
       "[57638 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"clarin-knext/fiqa-pl\", \"corpus\")\n",
    "dataset = load_dataset(\"clarin-knext/fiqa-pl\", 'corpus')\n",
    "df = dataset['corpus'].to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57638 documents loaded to index 'fiqa-pl-index'\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch.helpers import bulk, BulkIndexError\n",
    "\n",
    "def load_data_to_es(index_name, data):\n",
    "    \"\"\"Function to load data into the index in Elasticsearch\"\"\"\n",
    "    actions = [\n",
    "        {\n",
    "            \"_index\": index_name,\n",
    "            \"_id\": doc[\"_id\"],\n",
    "            \"_source\": {\n",
    "                \"with_synonyms\": doc[\"text\"],\n",
    "                \"without_synonyms\": doc[\"text\"]\n",
    "                }\n",
    "        }\n",
    "        for doc in data\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        success, _ = bulk(es, actions)\n",
    "        print(f\"{success} documents loaded to index '{index_name}'\")\n",
    "    except BulkIndexError as e:\n",
    "        print(f\"{len(e.errors)} documents failed to load.\")\n",
    "        for error in e.errors:\n",
    "            print(error)\n",
    "\n",
    "index_name = 'fiqa-pl-index'\n",
    "load_data_to_es(index_name, ds['corpus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Determine the number of documents and the number of matches containing the word kwiecień (in any form) including and excluding the synonyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches, including synonyms: 306\n",
      "Matches, without synonyms: 257\n"
     ]
    }
   ],
   "source": [
    "matches_with_synonyms = es.count(index=index_name, body={\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"with_synonyms\": \"kwiecień\"  \n",
    "        }\n",
    "    }\n",
    "})['count']\n",
    "print(f\"Matches, including synonyms: {matches_with_synonyms}\")\n",
    "\n",
    "matches_without_synonyms = es.count(index=index_name, body={\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"without_synonyms\": \"kwiecień\"\n",
    "        }\n",
    "    }\n",
    "})['count']\n",
    "print(f\"Matches, without synonyms: {matches_without_synonyms}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Download the QA pairs for the FiQA-PL dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "queries_dataset = load_dataset('clarin-knext/fiqa-pl', 'queries')\n",
    "corpus_dataset = load_dataset('clarin-knext/fiqa-pl', 'corpus')\n",
    "qrels_dataset = load_dataset('clarin-knext/fiqa-pl-qrels', 'default')\n",
    "\n",
    "queries = queries_dataset['queries'].to_pandas()\n",
    "corpus = corpus_dataset['corpus'].to_pandas()\n",
    "qrels = qrels_dataset['test'].to_pandas()\n",
    "\n",
    "qrels['corpus-id'] = qrels['corpus-id'].astype(int)\n",
    "corpus['_id'] = corpus['_id'].astype(int)\n",
    "queries['_id'] = queries['_id'].astype(int)\n",
    "qa_pairs = pd.merge(qrels, corpus, left_on=\"corpus-id\", right_on=\"_id\", how=\"left\")\n",
    "final_output = pd.merge(qa_pairs, queries, left_on=\"query-id\", right_on=\"_id\", suffixes=('_corpus', '_query'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>score</th>\n",
       "      <th>_id_corpus</th>\n",
       "      <th>title_corpus</th>\n",
       "      <th>text_corpus</th>\n",
       "      <th>_id_query</th>\n",
       "      <th>title_query</th>\n",
       "      <th>text_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>566392</td>\n",
       "      <td>1</td>\n",
       "      <td>566392</td>\n",
       "      <td></td>\n",
       "      <td>Poproś o ponowne wystawienie czeku właściwemu ...</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>Jak zdeponować czek wystawiony na współpracown...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>65404</td>\n",
       "      <td>1</td>\n",
       "      <td>65404</td>\n",
       "      <td></td>\n",
       "      <td>Po prostu poproś współpracownika o podpisanie ...</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>Jak zdeponować czek wystawiony na współpracown...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>325273</td>\n",
       "      <td>1</td>\n",
       "      <td>325273</td>\n",
       "      <td></td>\n",
       "      <td>Oczywiście że możesz. W sekcji Od przekazu pie...</td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td>Czy mogę wysłać przekaz pieniężny z USPS jako ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>88124</td>\n",
       "      <td>1</td>\n",
       "      <td>88124</td>\n",
       "      <td></td>\n",
       "      <td>Mylisz tutaj wiele rzeczy. Spółka B LLC będzie...</td>\n",
       "      <td>18</td>\n",
       "      <td></td>\n",
       "      <td>1 EIN prowadzący działalność pod wieloma nazwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>285255</td>\n",
       "      <td>1</td>\n",
       "      <td>285255</td>\n",
       "      <td></td>\n",
       "      <td>„Obawiam się, że wielkim mitem spółek z ograni...</td>\n",
       "      <td>26</td>\n",
       "      <td></td>\n",
       "      <td>Ubieganie się o kredyt biznesowy i otrzymywani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>11039</td>\n",
       "      <td>330058</td>\n",
       "      <td>1</td>\n",
       "      <td>330058</td>\n",
       "      <td></td>\n",
       "      <td>Zdecydowanie wkładałbym wystarczająco dużo, ab...</td>\n",
       "      <td>11039</td>\n",
       "      <td></td>\n",
       "      <td>Spłać zadłużenie karty kredytowej lub zarób 40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>11039</td>\n",
       "      <td>91183</td>\n",
       "      <td>1</td>\n",
       "      <td>91183</td>\n",
       "      <td></td>\n",
       "      <td>„Istnieje bardzo proste obliczenie, które odpo...</td>\n",
       "      <td>11039</td>\n",
       "      <td></td>\n",
       "      <td>Spłać zadłużenie karty kredytowej lub zarób 40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>11054</td>\n",
       "      <td>155053</td>\n",
       "      <td>1</td>\n",
       "      <td>155053</td>\n",
       "      <td></td>\n",
       "      <td>„Nie ma specjalnej stawki dla krótkoterminowyc...</td>\n",
       "      <td>11054</td>\n",
       "      <td></td>\n",
       "      <td>Podatek od krótkoterminowych zysków kapitałowy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>11054</td>\n",
       "      <td>321015</td>\n",
       "      <td>1</td>\n",
       "      <td>321015</td>\n",
       "      <td></td>\n",
       "      <td>„Najważniejsze jest to: w Stanach Zjednoczonyc...</td>\n",
       "      <td>11054</td>\n",
       "      <td></td>\n",
       "      <td>Podatek od krótkoterminowych zysków kapitałowy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>11088</td>\n",
       "      <td>437100</td>\n",
       "      <td>1</td>\n",
       "      <td>437100</td>\n",
       "      <td></td>\n",
       "      <td>„Nie jest to porada prawna i obejmuje jedynie ...</td>\n",
       "      <td>11088</td>\n",
       "      <td></td>\n",
       "      <td>Czy wymagane jest, aby prawnik stworzył/nadzor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1706 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      query-id  corpus-id  score  _id_corpus title_corpus  \\\n",
       "0            8     566392      1      566392                \n",
       "1            8      65404      1       65404                \n",
       "2           15     325273      1      325273                \n",
       "3           18      88124      1       88124                \n",
       "4           26     285255      1      285255                \n",
       "...        ...        ...    ...         ...          ...   \n",
       "1701     11039     330058      1      330058                \n",
       "1702     11039      91183      1       91183                \n",
       "1703     11054     155053      1      155053                \n",
       "1704     11054     321015      1      321015                \n",
       "1705     11088     437100      1      437100                \n",
       "\n",
       "                                            text_corpus  _id_query  \\\n",
       "0     Poproś o ponowne wystawienie czeku właściwemu ...          8   \n",
       "1     Po prostu poproś współpracownika o podpisanie ...          8   \n",
       "2     Oczywiście że możesz. W sekcji Od przekazu pie...         15   \n",
       "3     Mylisz tutaj wiele rzeczy. Spółka B LLC będzie...         18   \n",
       "4     „Obawiam się, że wielkim mitem spółek z ograni...         26   \n",
       "...                                                 ...        ...   \n",
       "1701  Zdecydowanie wkładałbym wystarczająco dużo, ab...      11039   \n",
       "1702  „Istnieje bardzo proste obliczenie, które odpo...      11039   \n",
       "1703  „Nie ma specjalnej stawki dla krótkoterminowyc...      11054   \n",
       "1704  „Najważniejsze jest to: w Stanach Zjednoczonyc...      11054   \n",
       "1705  „Nie jest to porada prawna i obejmuje jedynie ...      11088   \n",
       "\n",
       "     title_query                                         text_query  \n",
       "0                 Jak zdeponować czek wystawiony na współpracown...  \n",
       "1                 Jak zdeponować czek wystawiony na współpracown...  \n",
       "2                 Czy mogę wysłać przekaz pieniężny z USPS jako ...  \n",
       "3                 1 EIN prowadzący działalność pod wieloma nazwa...  \n",
       "4                 Ubieganie się o kredyt biznesowy i otrzymywani...  \n",
       "...          ...                                                ...  \n",
       "1701              Spłać zadłużenie karty kredytowej lub zarób 40...  \n",
       "1702              Spłać zadłużenie karty kredytowej lub zarób 40...  \n",
       "1703              Podatek od krótkoterminowych zysków kapitałowy...  \n",
       "1704              Podatek od krótkoterminowych zysków kapitałowy...  \n",
       "1705              Czy wymagane jest, aby prawnik stworzył/nadzor...  \n",
       "\n",
       "[1706 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Compute NDCG@5 for the QA dataset (the test subset) for the following setusp:\n",
    "- synonyms enabled and disabled,\n",
    "- lemmatization in the query enabled and disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_settings_no_lematization = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"filter\": {\n",
    "                \"synonym\": {\n",
    "                    \"type\": \"synonym\",\n",
    "                    \"synonyms\": [\n",
    "                        \"styczeń, sty, I\",\n",
    "                        \"luty, lut, II\",\n",
    "                        \"marzec, mar, III\",\n",
    "                        \"kwiecień, kwi, IV\",\n",
    "                        \"maj, V\",\n",
    "                        \"czerwiec, cze, VI\",\n",
    "                        \"lipiec, lip, VII\",\n",
    "                        \"sierpień, sie, VIII\",\n",
    "                        \"wrzesień, wrz, IX\",\n",
    "                        \"październik, paź, X\",\n",
    "                        \"listopad, lis, XI\",\n",
    "                        \"grudzień, gru, XII\"\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"analyzer\": {\n",
    "                \"polish_analyzer_with_synonyms_no_lem\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\"synonym\", \"lowercase\", \"lowercase\"]\n",
    "                },\n",
    "                \"polish_analyzer_without_synonyms_no_lem\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\"lowercase\", \"lowercase\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\" : {\n",
    "        \"properties\": {\n",
    "            \"with_synonyms_no_lem\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"polish_analyzer_with_synonyms_no_lem\"\n",
    "            },\n",
    "            \"without_synonyms_no_lem\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"polish_analyzer_without_synonyms_no_lem\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gboch\\AppData\\Local\\Temp\\ipykernel_4460\\912292633.py:4: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  es.indices.create(index=index_name_no_lem, body=analysis_settings_no_lematization, ignore=400)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'fiqa-pl-index_no_lem'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name_no_lem = \"fiqa-pl-index_no_lem\"\n",
    "if es.indices.exists(index=index_name_no_lem):\n",
    "    es.indices.delete(index=index_name_no_lem)\n",
    "es.indices.create(index=index_name_no_lem, body=analysis_settings_no_lematization, ignore=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57638 documents loaded to index 'fiqa-pl-index_no_lem'\n"
     ]
    }
   ],
   "source": [
    "def load_data_to_es_no_lem(index_name_no_lem, data):\n",
    "    actions = [\n",
    "        {\n",
    "            \"_index\": index_name_no_lem,\n",
    "            \"_id\": doc[\"_id\"],\n",
    "            \"_source\": {\n",
    "                \"with_synonyms_no_lem\": doc[\"text\"],\n",
    "                \"without_synonyms_no_lem\": doc[\"text\"]\n",
    "            }\n",
    "        }\n",
    "        for doc in data\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        success, _ = bulk(es, actions)\n",
    "        print(f\"{success} documents loaded to index '{index_name_no_lem}'\")\n",
    "    except BulkIndexError as e:\n",
    "        print(f\"{len(e.errors)} documents failed to load.\")\n",
    "        for error in e.errors:\n",
    "            print(error)\n",
    "\n",
    "\n",
    "load_data_to_es_no_lem(index_name_no_lem, ds['corpus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "queries_dataset = load_dataset(\"clarin-knext/fiqa-pl\", \"queries\")\n",
    "queries = queries_dataset['queries']\n",
    "queries = queries.to_pandas()\n",
    "\n",
    "qa_dataset = load_dataset(\"clarin-knext/fiqa-pl-qrels\")\n",
    "test_data = qa_dataset['test']\n",
    "qrels = test_data.to_pandas()\n",
    "\n",
    "\n",
    "def calc_ndcg_k(true, predicted):\n",
    "    \"\"\"Function to calculate Normalized Discounted Cumulative Gain (NDCG) at rank k\"\"\"\n",
    "    dcg = np.sum(predicted / np.log2(np.arange(2, len(true) + 2)))\n",
    "    idcg = np.sum(true / np.log2(np.arange(2, len(true) + 2)))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "\n",
    "def count_ndcg(index, maps):\n",
    "    \"\"\"Function to count NDCG across queries\"\"\"\n",
    "    max_matches = qrels.groupby('query-id')['corpus-id'].count().rename('count')\n",
    "    \n",
    "    ndcg_total = 0  \n",
    "    num_queries = 0  \n",
    "\n",
    "    for query_id in qrels['query-id'].unique():\n",
    "        query = queries.loc[queries['_id'] == str(query_id), 'text'].iloc[0]\n",
    "\n",
    "        query_blank = {\n",
    "            \"match\": {\n",
    "                maps: {\n",
    "                    \"query\": query\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        resp = es.search(index=index, query=query_blank)\n",
    "        corpus_ids = qrels.loc[qrels['query-id'] == query_id, 'corpus-id'].tolist()\n",
    "\n",
    "        matches = min(max_matches.loc[query_id], 5)\n",
    "        true = np.array([1 if i < matches else 0 for i in range(5)])\n",
    "        \n",
    "        predicted = np.zeros(5)\n",
    "\n",
    "        for i, hit in enumerate(resp['hits']['hits'][:5]):\n",
    "            predicted[i] = 1 if int(hit['_id']) in corpus_ids else 0\n",
    "        ndcg_total += calc_ndcg_k(true, predicted)\n",
    "        num_queries += 1\n",
    "\n",
    "    return ndcg_total / num_queries if num_queries > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average NDCG is 0.18512911307977398 for the index with synonyms and lemmatization.\n"
     ]
    }
   ],
   "source": [
    "mean_ndcg = count_ndcg(\"fiqa-pl-index\", \"with_synonyms\")\n",
    "print(f\"The average NDCG is {mean_ndcg} for the index with synonyms and lemmatization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average NDCG is 0.18512911307977398 for the index without synonyms and lemmatization.\n"
     ]
    }
   ],
   "source": [
    "mean_ndcg = count_ndcg(\"fiqa-pl-index\", \"without_synonyms\")\n",
    "print(f\"The average NDCG is {mean_ndcg} for the index without synonyms and lemmatization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average NDCG is 0.13854570378524383 for the index with synonyms and no lemmatization.\n"
     ]
    }
   ],
   "source": [
    "mean_ndcg = count_ndcg(\"fiqa-pl-index_no_lem\", \"with_synonyms_no_lem\")\n",
    "print(f\"The average NDCG is {mean_ndcg} for the index with synonyms and no lemmatization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average NDCG is 0.13854570378524383 for the index with synonyms and lemmatization.\n"
     ]
    }
   ],
   "source": [
    "mean_ndcg = count_ndcg(\"fiqa-pl-index_no_lem\", \"without_synonyms_no_lem\")\n",
    "print(f\"The average NDCG is {mean_ndcg} for the index with synonyms and lemmatization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = es.cat.indices(format=\"json\")\n",
    "# index_names = [index['index'] for index in indices]\n",
    "# print(index_names)\n",
    "\n",
    "# for index in index_names:\n",
    "#     es.indices.delete(index=index)\n",
    "#     print(f\"Usunięto indeks: {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What are the strengths and weaknesses of regular expressions versus full text search regarding processing of text?\n",
    "\n",
    "Wyrażenia regularne:\n",
    "- Umożliwiają bardzo precyzyjne dopasowanie określonych wzorców w tekście\n",
    "- Zapewniają precyzyjną kontrolę nad wyszukiwaniem, np. określonych słów w określonych kontekstach.\n",
    "- Są dobre w rozpoznawaniu niekompletnych lub niejednoznacznych wzorców, ale są ograniczone do tego, co programuje użytkownik.\n",
    "- Działają na poziomie znaków, nie biorąc pod uwagę znaczenia i kontekstu słów.\n",
    "- Łatwiejsze w użyciu\n",
    "\n",
    "Wyszukiwanie pełnotekstowe (FTS):\n",
    "- Zoptymalizowane do szybkiego wyszukiwania dużych zestawów danych (np. ElasticSearch).\n",
    "- Obsługuje lematyzację, stemming i synonimy, co zwiększa dokładność wyszukiwań opartych na znaczeniu.\n",
    "- Mniej precyzyjne niż wyrażenia regularne, ponieważ działa na indeksie słów (nie zawsze: wszystko zależy od tego, jakiego wyrażenia regularnego użył użytkownik)\n",
    "- Wymaga bardziej złożonej konfiguracji i ponownego indeksowania po zmianach danych.\n",
    "- Wyniki nie są tak rozbieżne, nie zależą od tego, co użytkownik wpisuje/myśli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Can an LLM be applied in the context of searching for documents? Justify your answer, excluding the obvious observation that an LLM can be used to formulate the answer.\n",
    "\n",
    "Tak, modele językowe (LLM) mogą obsługiwać wyszukiwanie dokumentów w zaawansowanych scenariuszach:\n",
    "\n",
    "- LLM rozumieją semantykę i intencję zapytań, wykraczając poza prostą analizę słów kluczowych.\n",
    "- Mogą generować podsumowania dokumentów i kluczowe informacje, ułatwiając przeglądanie wyników.\n",
    "- Rozpoznają warianty językowe, synonimy i różne style.\n",
    "- Uzupełniają zapytania i lepiej dopasowują dokumenty, nawet jeśli zapytanie jest nieprecyzyjne.\n",
    "- Umożliwiają personalizację wyników na podstawie preferencji użytkownika.\n",
    "- Mogą rekomendować dokumenty powiązane z poprzednimi wyszukiwaniami."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
